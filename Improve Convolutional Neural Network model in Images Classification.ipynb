{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Improve Convolutional Neural Network model in Images Classification</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "\n",
    "0. [Title and author](#Title-and-author:)\n",
    "\n",
    "\n",
    "1. [Introduction](#Introduction:)\n",
    "\n",
    "\n",
    "2. [Dataset](#Dataset:)\n",
    "\n",
    "\n",
    "3. [Methodology](#Methodology:)\n",
    "\n",
    "\n",
    "4. [Results](#Results:)\n",
    "\n",
    "\n",
    "5. [References](#References:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title and author:\n",
    "1. <b>Title</b>:\n",
    "<center><i>Improve Convolutional Neural Network model in Images Classification</i></center>\n",
    "\n",
    "2. <b>Author</b>:\n",
    "    - Name: Thai Quoc Hoang\n",
    "    - Date of birth: January 09, 2000\n",
    "    - Email: quocthai9120@gmail.com / qthai912@uw.edu\n",
    "    - GitHub: https://github.com/quocthai9120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "This project is done based on the result from the final research project in the CSE163 course from University of Washington about Using different models in Image Classification. The link below gives more information about that research project: https://github.com/quocthai9120/Images-Classification.\n",
    "\n",
    "The previous result ends up with 70.09% correct accuracy for 10000 testing instances using the CIFAR_10 dataset. This is not a bad start for the image classification task. However, we need to improve the model significantly if we want to use in real-life classification tasks.\n",
    "\n",
    "This project focuses on experimenting with different methods to improve the Convolutional Neural Network model that used to image classification using the CIFAR_10 dataset, including data preprocessing, pre-trained model modification, and training modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:\n",
    "\n",
    "\n",
    "## CIFAR_10 dataset:\n",
    "\n",
    "### Source and Information:\n",
    "The CIFAR-10 dataset contains 60000 32x32 colour images in 10 classes (6000 images/class) that are randomly shuffled and are divided into 2 parts:\n",
    "- 50000 images for training (5000 images for each class).\n",
    "- 10000 images for testing (1000 images for each class).\n",
    "\n",
    "The classes are completely mutually exclusive and there is no overlap between classes.\n",
    "\n",
    "10 classes of CIFAR-10 dataset are:\n",
    "0. airplane\n",
    "1. automobile\n",
    "2. bird\n",
    "3. cat\n",
    "4. deer\n",
    "5. dog\n",
    "6. frog\n",
    "7. horse\n",
    "8. ship\n",
    "9. truck\n",
    "\n",
    "The dataset were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton and can be accessed through the link provided here : https://www.cs.toronto.edu/~kriz/cifar.html or directly download here: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz.\n",
    "\n",
    "### Dataset layout:\n",
    "The CIFAR-10 datset used in this project is the Python Version.\n",
    "\n",
    "The download compressed file contains 7 files: data_batch_1, data_batch_2, data_batch_4, data_batch_5,test_batch, and batches.meta, which are Python \"pickled\" objects.\n",
    "\n",
    "The source of the dataset (https://www.cs.toronto.edu/~kriz/cifar.html) provides a function called 'unpickle(file)' to open such files and returns the data as dictionaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "\n",
    "- The project has a 85.25% correct accuracy using 10000 testing instances for classification, which is increased 15.16% from 70.09% as the previous project. Using several images from testing set to compare two models: <img src=\"Supporting Files/Improved Results/CNN predictions.png\" style=\"width: 1000px\"/>\n",
    "\n",
    "- Using the first ten examples in test set and compute the probabilities for each label, we got the results for the previous model and the improved model:\n",
    "    + Previous model: <img src=\"cifar-10-batches-py/Images/CNN predictions probabilities.jpg\" style=\"width: 1000px\"/>\n",
    "    + Improved model: <img src=\"Supporting Files/Improved Results/CNN predictions probabilities.png\" style=\"width: 1000px\"/>\n",
    "\n",
    "    + As the 10 examples are shuffled randomly, the results can represent the trend of the CIFAR_10 dataset. From the results we have produced, we recognize the fact that for most images in this dataset, the improved CNN model gives predictions with higher confidence because along with the high value of resulted label's probabilities, the improved model reduces the probabilities of wrong predictions (the values of other labels) that we can refer to the loss of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "1. CS231n Convolutional Neural Networks for Visual Recognition - Data Preprocessing: http://cs231n.github.io/neural-networks-2/#datapre\n",
    "\n",
    "2. Jason Brownlee. A Gentle Introduction to Early Stopping to Avoid Overtraining Deep Learning Neural Network Models: https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/\n",
    "\n",
    "3. Sergey Ioffe, Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift: https://arxiv.org/pdf/1502.03167v3.pdf\n",
    "\n",
    "4. Francois Chollet. Building powerful image classification models using very little data: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "5. Mikhail Belkin, Daniel Hsu, Siyuan Ma , and Soumik Mandal. Reconciling modern machine learning and the bias-variance trade-off: https://arxiv.org/pdf/1812.11118.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
